# Whisper 语音识别模型使用指南

## 环境准备

本项目已经创建了名为 `transformers` 的虚拟环境，并安装了必要的依赖。每次使用前，请先激活该环境：

```bash
source transformers/bin/activate
```

## 脚本介绍

本项目包含三个脚本，从简单到复杂，适合不同需求：

### 1. 快速入门脚本 (whisper_quick.py)

最简单的脚本，适合初次尝试：

```bash
python whisper_quick.py
```

运行后，按提示输入音频文件路径即可。

### 2. 演示脚本 (whisper_demo.py)

包含下载模型到本地的功能：

```bash
python whisper_demo.py
```

修改脚本中的 `audio_file` 变量为你的音频文件路径。

### 3. 高级脚本 (whisper_advanced.py)

功能完整的命令行工具，支持多语言、批量处理等高级功能：

```bash
# 查看帮助
python whisper_advanced.py --help

# 基本用法（交互模式）
python whisper_advanced.py

# 指定音频文件
python whisper_advanced.py --audio 你的音频文件.mp3

# 指定语言（中文）
python whisper_advanced.py --audio 你的音频文件.mp3 --language zh

# 翻译成英文
python whisper_advanced.py --audio 你的音频文件.mp3 --task translate

# 下载模型到本地
python whisper_advanced.py --download --model openai/whisper-large-v3

# 批量处理文件夹中的所有音频
python whisper_advanced.py --audio 音频文件夹路径 --output_dir 输出文件夹路径
```

## 常用命令参数

高级脚本支持以下参数：

- `--audio`：音频文件或文件夹路径
- `--model`：模型名称或本地路径（默认为 openai/whisper-large-v3）
- `--language`：语言代码，如 zh（中文）、en（英文）、auto（自动检测）
- `--task`：任务类型，transcribe（转录）或 translate（翻译成英文）
- `--output_dir`：输出文件夹路径
- `--device`：计算设备，auto、cpu、mps（Mac M 系列芯片）、cuda（NVIDIA GPU）
- `--download`：下载模型到本地
- `--local_dir`：本地模型保存路径

## 使用技巧

1. **首次使用时**：
   - 首次运行会自动下载模型，需要良好的网络连接
   - 模型文件较大（约 2-3GB），下载需要一定时间

2. **MPS 加速**：
   - 对于 MacBook M 系列芯片，脚本会自动使用 MPS 加速
   - MPS 相比 CPU 可显著提升处理速度

3. **语言支持**：
   - Whisper 支持近 100 种语言的自动识别
   - 对于中文识别，可以明确指定 `--language zh` 提高准确性

4. **批量处理**：
   - 使用高级脚本可以一次处理整个文件夹的音频
   - 结果会保存在指定的输出目录中

5. **选择合适的模型**：
   - large-v3：最大最精确，但速度较慢
   - medium：平衡速度和精度
   - small/base/tiny：小而快，适合简单场景或资源受限设备

6. **本地模型使用**：
   - 使用 `--download` 参数下载模型后，可离线使用
   - 后续可以使用 `--model` 指向本地模型路径

## 常见问题解决

1. **内存不足**：
   - 处理较长音频时可能需要较多内存
   - 尝试使用较小的模型（如 medium 或 small）

2. **转录不准确**：
   - 指定正确的语言可提高准确性
   - 确保音频质量清晰，背景噪音小

3. **速度较慢**：
   - 确保使用 MPS 或 CUDA 加速
   - 对于批量处理，建议使用较小的模型

4. **模型下载失败**：
   - 检查网络连接
   - 尝试使用代理或更换网络环境 